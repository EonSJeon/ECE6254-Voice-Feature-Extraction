{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File-existence filtered accent counts:\n",
      "accent\n",
      "england      14648\n",
      "indian        4382\n",
      "australia     4020\n",
      "african       1133\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# === df_train + df_valid ===\n",
    "BASE_DIR = '/Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/'\n",
    "RAW_DATA_DIR = os.path.join(BASE_DIR, 'raw_data')\n",
    "TRAIN_CSV_PATH = os.path.join(RAW_DATA_DIR, 'cv-valid-train.csv')\n",
    "\n",
    "accents = ['england', 'indian', 'australia', 'african']\n",
    "ages = ['teens', 'twenties', 'thirties', 'fourties', 'fifties', 'sixties']\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "\n",
    "# Drop rows with missing gender\n",
    "df_train = df_train.dropna(subset=['gender'])\n",
    "\n",
    "# Filter accents of interest\n",
    "df_train = df_train[df_train['accent'].isin(accents)]\n",
    "\n",
    "# Drop rows with missing accent\n",
    "df_train = df_train.dropna(subset=['accent'])\n",
    "\n",
    "# Check if each file exists in RAW_DATA_DIR and remove rows where file is missing\n",
    "df_train = df_train[df_train['filename'].apply(lambda x: os.path.exists(os.path.join(RAW_DATA_DIR, x)))]\n",
    "\n",
    "\n",
    "df_train = df_train[['filename', 'gender', 'accent', 'age']]\n",
    "\n",
    "print(\"File-existence filtered accent counts:\")\n",
    "print(df_train['accent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File-existence filtered accent counts for test set:\n",
      "accent\n",
      "england      298\n",
      "indian        90\n",
      "australia     90\n",
      "african       24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# === df_test ===\n",
    "TEST_CSV_PATH = os.path.join(RAW_DATA_DIR, 'cv-valid-test.csv')\n",
    "\n",
    "df_test = pd.read_csv(TEST_CSV_PATH)\n",
    "\n",
    "# Drop rows with missing gender\n",
    "df_test = df_test.dropna(subset=['gender'])\n",
    "\n",
    "# Filter accents of interest\n",
    "df_test = df_test[df_test['accent'].isin(accents)]\n",
    "\n",
    "# Drop rows with missing accent\n",
    "df_test = df_test.dropna(subset=['accent'])\n",
    "\n",
    "# Check if each file exists in RAW_DATA_DIR and remove rows where file is missing\n",
    "df_test = df_test[df_test['filename'].apply(lambda x: os.path.exists(os.path.join(RAW_DATA_DIR, x)))]\n",
    "\n",
    "df_test = df_test[['filename', 'gender', 'accent', 'age']]\n",
    "\n",
    "print(\"File-existence filtered accent counts for test set:\")\n",
    "print(df_test['accent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resample factor information saved to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/train_dataset_info.txt\n"
     ]
    }
   ],
   "source": [
    "# Work on a copy of the training data\n",
    "df_temp = df_train.copy()\n",
    "\n",
    "# Get all unique accents and count them\n",
    "all_accents = df_temp['accent'].unique()\n",
    "num_accents = len(all_accents)\n",
    "\n",
    "# Identify (gender, age) combinations that are present in every accent\n",
    "combo_counts = df_temp.groupby(['gender', 'age'])['accent'].nunique()\n",
    "valid_combos = combo_counts[combo_counts == num_accents].index.tolist()\n",
    "\n",
    "balanced_groups = []\n",
    "resample_info_lines = []  # List to store resample factor info\n",
    "\n",
    "# Process each valid (gender, age) combination\n",
    "for gender, age in valid_combos:\n",
    "    # Subset data for the current (gender, age) cell\n",
    "    subset = df_temp[(df_temp['gender'] == gender) & (df_temp['age'] == age)]\n",
    "    \n",
    "    # Compute available counts per accent for this cell\n",
    "    accent_counts = subset.groupby('accent').size()\n",
    "    \n",
    "    # Determine the target T: cannot exceed 1.5 times the minimum count and must be at most the maximum available count.\n",
    "    T = min(accent_counts.max(), int(1.5 * accent_counts.min()))\n",
    "    \n",
    "    # For each accent, sample T records: oversample (with replacement) if needed or undersample otherwise.\n",
    "    for accent, group in subset.groupby('accent'):\n",
    "        current_count = len(group)\n",
    "        factor = T / current_count\n",
    "        if current_count < T:\n",
    "            method = 'oversampled'\n",
    "            sampled = group.sample(n=T, replace=True, random_state=42)\n",
    "        else:\n",
    "            method = 'undersampled'\n",
    "            sampled = group.sample(n=T, replace=False, random_state=42)\n",
    "        balanced_groups.append(sampled)\n",
    "        \n",
    "        # Record resample factor info for this group\n",
    "        info_line = (f\"Gender: {gender}, Age: {age}, Accent: {accent}, \"\n",
    "                     f\"Original count: {current_count}, Target count: {T}, \"\n",
    "                     f\"Factor: {factor:.2f} ({method})\")\n",
    "        resample_info_lines.append(info_line)\n",
    "\n",
    "\n",
    "df_balanced = pd.concat(balanced_groups, ignore_index=True)\n",
    "\n",
    "\n",
    "# Save resample factor information to a text file\n",
    "output_dir = os.path.join(BASE_DIR, \"data\")  # Using absolute path\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "resample_txt_path = os.path.join(output_dir, 'train_dataset_info.txt')\n",
    "with open(resample_txt_path, \"w\") as f:\n",
    "    f.write(\"Resample Factor Information:\\n\")\n",
    "    for line in resample_info_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "print(\"Resample factor information saved to\", resample_txt_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples per accent:\n",
      "accent\n",
      "african      1264\n",
      "australia    1264\n",
      "england      1264\n",
      "indian       1264\n",
      "dtype: int64\n",
      "Balanced Accent x Age Confusion Matrix:\n",
      "age        fifties  fourties  sixties  teens  thirties  twenties\n",
      "accent                                                          \n",
      "african        107        67       48    180       382       480\n",
      "australia      107        67       48    180       382       480\n",
      "england        107        67       48    180       382       480\n",
      "indian         107        67       48    180       382       480\n",
      "\n",
      "Balanced Accent x Gender Confusion Matrix:\n",
      "gender     female  male\n",
      "accent                 \n",
      "african       230  1034\n",
      "australia     230  1034\n",
      "england       230  1034\n",
      "indian        230  1034\n",
      "\n",
      "Total number of records in balanced dataset: 5056\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of samples per accent to verify they are equal\n",
    "accent_totals = df_balanced.groupby('accent').size()\n",
    "print(\"\\nTotal samples per accent:\")\n",
    "print(accent_totals)\n",
    "\n",
    "# Display the balanced Accent x Age confusion matrix\n",
    "confusion_matrix_age = pd.crosstab(df_balanced['accent'], df_balanced['age'])\n",
    "print(\"Balanced Accent x Age Confusion Matrix:\")\n",
    "print(confusion_matrix_age)\n",
    "\n",
    "# Display the balanced Accent x Gender confusion matrix\n",
    "confusion_matrix_gender = pd.crosstab(df_balanced['accent'], df_balanced['gender'])\n",
    "print(\"\\nBalanced Accent x Gender Confusion Matrix:\")\n",
    "print(confusion_matrix_gender)\n",
    "\n",
    "print(f\"\\nTotal number of records in balanced dataset: {len(df_balanced)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accent counts in validation set:\n",
      "accent\n",
      "australia    500\n",
      "england      500\n",
      "indian       500\n",
      "african      436\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exclude rows that are in df_balanced from df_train\n",
    "df_valid_candidate = df_train[~df_train['filename'].isin(df_balanced['filename'])]\n",
    "\n",
    "balanced_valid_groups = []\n",
    "# For each accent, sample exactly 500 records to balance the accent distribution.\n",
    "# (If a group has less than 500 records, it will sample all available records.)\n",
    "for accent, group in df_valid_candidate.groupby('accent'):\n",
    "    n_samples = 500 if len(group) >= 500 else len(group)\n",
    "    sampled_group = group.sample(n=n_samples, random_state=42)\n",
    "    balanced_valid_groups.append(sampled_group)\n",
    "\n",
    "# Combine the groups to create the balanced validation DataFrame\n",
    "df_valid = pd.concat(balanced_valid_groups, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Print the number of samples per accent in the validation set\n",
    "accent_counts = df_valid['accent'].value_counts()\n",
    "print(\"Accent counts in validation set:\")\n",
    "print(accent_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset accent counts:\n",
      "accent_encoded\n",
      "0    1264\n",
      "1    1264\n",
      "2    1264\n",
      "3    1264\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation dataset accent counts:\n",
      "accent_encoded\n",
      "1    500\n",
      "2    500\n",
      "3    500\n",
      "0    436\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label classes:\n",
      "['african' 'australia' 'england' 'indian']\n",
      "Accent label mapping appended to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/label_mapping_info.txt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# Create a label encoder and fit on the 'accent' column of df_balanced\n",
    "label_encoder = LabelEncoder()\n",
    "df_balanced['accent_encoded'] = label_encoder.fit_transform(df_balanced['accent'])\n",
    "\n",
    "# Use the same label encoder to transform the 'accent' column of df_valid\n",
    "df_valid['accent_encoded'] = label_encoder.transform(df_valid['accent'])\n",
    "\n",
    "df_test['accent_encoded'] = label_encoder.transform(df_test['accent'])\n",
    "\n",
    "# Print counts for verification\n",
    "print(\"Balanced dataset accent counts:\")\n",
    "print(df_balanced['accent_encoded'].value_counts())\n",
    "print(\"\\nValidation dataset accent counts:\")\n",
    "print(df_valid['accent_encoded'].value_counts())\n",
    "print(\"\\nLabel classes:\")\n",
    "print(label_encoder.classes_)\n",
    "\n",
    "# Append the accent label mapping information to the existing info text file\n",
    "txt_out_path = os.path.join(BASE_DIR, 'data', 'label_mapping_info.txt')\n",
    "with open(txt_out_path, \"a\") as f:  # open in append mode\n",
    "    f.write(\"\\nAccent Label Mapping:\\n\")\n",
    "    for encoded_value, accent in enumerate(label_encoder.classes_):\n",
    "        f.write(f\"{encoded_value}: {accent}\\n\")\n",
    "\n",
    "print(\"Accent label mapping appended to\", txt_out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced validation DataFrame saved to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/df_valid.csv\n",
      "Balanced DataFrame saved to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/df_train_balanced.csv\n",
      "Test DataFrame saved to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/df_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the balanced validation DataFrame to a CSV file\n",
    "df_valid_csv_path = os.path.join(output_dir, 'df_valid.csv')\n",
    "df_valid.to_csv(df_valid_csv_path, index=False)\n",
    "print(\"Balanced validation DataFrame saved to\", df_valid_csv_path)\n",
    "\n",
    "# Save the balanced DataFrame to a CSV file in the same directory\n",
    "df_balanced_csv_path = os.path.join(output_dir, 'df_train_balanced.csv')\n",
    "df_balanced.to_csv(df_balanced_csv_path, index=False)\n",
    "print(\"Balanced DataFrame saved to\", df_balanced_csv_path)\n",
    "\n",
    "# Save the df_test DataFrame to a CSV file\n",
    "output_dir = os.path.join(BASE_DIR, 'data')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "df_test_csv_path = os.path.join(output_dir, 'df_test.csv')\n",
    "df_test.to_csv(df_test_csv_path, index=False)\n",
    "print(\"Test DataFrame saved to\", df_test_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed df_balance, df_valid, and df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC and tempogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features (MFCC & tempogram) for training set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train features: 100%|██████████| 5056/5056 [04:55<00:00, 17.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features (MFCC & tempogram) for validation set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid features: 100%|██████████| 1936/1936 [01:54<00:00, 16.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features (MFCC & tempogram) for test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test features: 100%|██████████| 502/502 [00:24<00:00, 20.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1754"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def lowpass_filter(data, sr, cutoff=4000, order=5):\n",
    "    \"\"\"\n",
    "    Apply a Butterworth low-pass filter to the data.\n",
    "    \n",
    "    Parameters:\n",
    "        data (np.ndarray): Audio time series.\n",
    "        sr (int): Sampling rate of the audio.\n",
    "        cutoff (float): Cutoff frequency in Hz (default 4000 Hz).\n",
    "        order (int): Filter order; higher order means a steeper rolloff.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Filtered audio signal.\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * sr\n",
    "    normal_cutoff = cutoff / nyquist  # normalize the frequency\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = lfilter(b, a, data)\n",
    "    return filtered_data\n",
    "\n",
    "def extract_features(file_path, h=13):\n",
    "    \"\"\"\n",
    "    Extract MFCC features and a tempogram with the same height (13 rows) from an audio file \n",
    "    after applying a low-pass filter.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to the audio file.\n",
    "        h (int): Number of MFCCs to extract (default 13 so that MFCC and tempogram heights are equal).\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (mfccs, tempogram) where:\n",
    "            - mfccs (np.ndarray): MFCC feature matrix with shape (13, time_frames).\n",
    "            - tempogram (np.ndarray): Tempogram feature matrix with 13 rows (time_frames).\n",
    "    \"\"\"\n",
    "    # Load the audio signal\n",
    "    audio, sr = librosa.load(file_path)\n",
    "    \n",
    "    # Apply low-pass filter to remove frequencies above 4000 Hz (using cutoff=5000 Hz here)\n",
    "    audio = lowpass_filter(audio, sr, cutoff=5000)\n",
    "    \n",
    "    # Define window and hop lengths based on the sampling rate\n",
    "    win_length = int(0.025 * sr)   # 25 ms window length\n",
    "    hop_length = int(0.01 * sr)    # 10 ms hop length\n",
    "    n_fft = win_length           # using window length as n_fft\n",
    "    \n",
    "    # Extract MFCC features with h=13 so that MFCC matrix has height 13.\n",
    "    mfccs = librosa.feature.mfcc(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_mfcc=h,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        win_length=win_length,\n",
    "        window='hann'\n",
    "    )\n",
    "    \n",
    "    # Compute onset envelope required for tempogram calculation\n",
    "    oenv = librosa.onset.onset_strength(y=audio, sr=sr, hop_length=hop_length)\n",
    "    \n",
    "    # Compute tempogram from the onset envelope\n",
    "    tempogram = librosa.feature.tempogram(onset_envelope=oenv, sr=sr, hop_length=hop_length)\n",
    "    \n",
    "    # Keep only the first 13 rows of the tempogram to match the MFCC height\n",
    "    tempogram = tempogram[:h, :]\n",
    "    \n",
    "    return mfccs, tempogram\n",
    "\n",
    "\n",
    "# === Process Training Data (df_balanced) ===\n",
    "all_features_train = []\n",
    "print(\"Extracting features (MFCC & tempogram) for training set:\")\n",
    "for idx, row in tqdm(df_balanced.iterrows(), total=len(df_balanced), desc=\"Train features\"):\n",
    "    path = os.path.join(RAW_DATA_DIR, row['filename'])\n",
    "    mfcc, tempogram = extract_features(path)\n",
    "    all_features_train.append((mfcc, tempogram))\n",
    "\n",
    "# === Process Validation Data (df_valid) ===\n",
    "all_features_valid = []\n",
    "print(\"Extracting features (MFCC & tempogram) for validation set:\")\n",
    "for idx, row in tqdm(df_valid.iterrows(), total=len(df_valid), desc=\"Valid features\"):\n",
    "    path = os.path.join(RAW_DATA_DIR, row['filename'])\n",
    "    mfcc, tempogram = extract_features(path)\n",
    "    all_features_valid.append((mfcc, tempogram))\n",
    "\n",
    "# === Process Test Data (df_test) ===\n",
    "all_features_test = []\n",
    "print(\"Extracting features (MFCC & tempogram) for test set:\")\n",
    "for idx, row in tqdm(df_test.iterrows(), total=len(df_test), desc=\"Test features\"):\n",
    "    path = os.path.join(RAW_DATA_DIR, row['filename'])\n",
    "    mfcc, tempogram = extract_features(path)\n",
    "    all_features_test.append((mfcc, tempogram))\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median time frames (train+valid+test): 388\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assume all_features_train, all_features_valid, all_features_test have been computed\n",
    "# Each element is a tuple: (mfcc, tempogram) where:\n",
    "#   mfcc has shape (n_mfcc, time_frames), e.g., (13, T)\n",
    "#   tempogram has shape (13, time_frames)\n",
    "\n",
    "# Compute the median number of time frames across training, validation, and test sets (using MFCC)\n",
    "time_frames_train = [features[0].shape[1] for features in all_features_train]\n",
    "time_frames_valid = [features[0].shape[1] for features in all_features_valid]\n",
    "time_frames_test = [features[0].shape[1] for features in all_features_test]\n",
    "all_time_frames = time_frames_train + time_frames_valid + time_frames_test\n",
    "median_time_frames = int(np.median(all_time_frames))\n",
    "print(\"Median time frames (train+valid+test):\", median_time_frames)\n",
    "\n",
    "# Define a helper function to pad or truncate a feature matrix along the time axis\n",
    "def pad_or_truncate(feature_matrix, target_length):\n",
    "    \"\"\"Pad with zeros or truncate the feature matrix along the time axis to have target_length frames.\"\"\"\n",
    "    current_length = feature_matrix.shape[1]\n",
    "    if current_length < target_length:\n",
    "        padded = np.pad(feature_matrix, ((0, 0), (0, target_length - current_length)), mode='constant')\n",
    "    else:\n",
    "        padded = feature_matrix[:, :target_length]\n",
    "    return padded\n",
    "\n",
    "# Process Training Data\n",
    "padded_mfccs_train = []\n",
    "padded_tempograms_train = []\n",
    "for mfcc, tempogram in all_features_train:\n",
    "    padded_mfccs_train.append(pad_or_truncate(mfcc, median_time_frames))\n",
    "    padded_tempograms_train.append(pad_or_truncate(tempogram, median_time_frames))\n",
    "\n",
    "# Process Validation Data\n",
    "padded_mfccs_valid = []\n",
    "padded_tempograms_valid = []\n",
    "for mfcc, tempogram in all_features_valid:\n",
    "    padded_mfccs_valid.append(pad_or_truncate(mfcc, median_time_frames))\n",
    "    padded_tempograms_valid.append(pad_or_truncate(tempogram, median_time_frames))\n",
    "\n",
    "# Process Test Data\n",
    "padded_mfccs_test = []\n",
    "padded_tempograms_test = []\n",
    "for mfcc, tempogram in all_features_test:\n",
    "    padded_mfccs_test.append(pad_or_truncate(mfcc, median_time_frames))\n",
    "    padded_tempograms_test.append(pad_or_truncate(tempogram, median_time_frames))\n",
    "\n",
    "# Combine MFCC and tempogram into a single feature by stacking along a new channel dimension.\n",
    "# For each sample, the combined feature shape will be (2, 13, median_time_frames)\n",
    "features_train = []\n",
    "for mfcc, tempogram in zip(padded_mfccs_train, padded_tempograms_train):\n",
    "    combined_feature = np.stack([mfcc, tempogram], axis=0)\n",
    "    features_train.append(combined_feature)\n",
    "\n",
    "features_valid = []\n",
    "for mfcc, tempogram in zip(padded_mfccs_valid, padded_tempograms_valid):\n",
    "    combined_feature = np.stack([mfcc, tempogram], axis=0)\n",
    "    features_valid.append(combined_feature)\n",
    "\n",
    "features_test = []\n",
    "for mfcc, tempogram in zip(padded_mfccs_test, padded_tempograms_test):\n",
    "    combined_feature = np.stack([mfcc, tempogram], axis=0)\n",
    "    features_test.append(combined_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training dataset to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/train-dataset.npz\n",
      "Saved validation dataset to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/valid-dataset.npz\n",
      "Saved test dataset to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/test-dataset.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create X arrays by stacking all combined features\n",
    "X_train = np.stack(features_train)   # Shape: (num_train, 2, 13, median_time_frames)\n",
    "X_valid = np.stack(features_valid)   # Shape: (num_valid, 2, 13, median_time_frames)\n",
    "X_test = np.stack(features_test)     # Shape: (num_test, 2, 13, median_time_frames)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(df_balanced['accent_encoded'].values)\n",
    "y_valid = to_categorical(df_valid['accent_encoded'].values)\n",
    "y_test = to_categorical(df_test['accent_encoded'].values)\n",
    "\n",
    "# Save each dataset to a compressed NPZ file\n",
    "output_dir = os.path.join(BASE_DIR, \"data\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "train_npz_path = os.path.join(output_dir, \"train-dataset.npz\")\n",
    "np.savez_compressed(train_npz_path, X=X_train, y=y_train)\n",
    "print(\"Saved training dataset to\", train_npz_path)\n",
    "\n",
    "valid_npz_path = os.path.join(output_dir, \"valid-dataset.npz\")\n",
    "np.savez_compressed(valid_npz_path, X=X_valid, y=y_valid)\n",
    "print(\"Saved validation dataset to\", valid_npz_path)\n",
    "\n",
    "test_npz_path = os.path.join(output_dir, \"test-dataset.npz\")\n",
    "np.savez_compressed(test_npz_path, X=X_test, y=y_test)\n",
    "print(\"Saved test dataset to\", test_npz_path)\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
