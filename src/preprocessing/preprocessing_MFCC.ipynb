{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             filename  gender  accent       age\n",
      "29   cv-valid-train/sample-000029.mp3    male  indian  thirties\n",
      "68   cv-valid-train/sample-000068.mp3    male  indian  twenties\n",
      "92   cv-valid-train/sample-000092.mp3    male  indian  twenties\n",
      "167  cv-valid-train/sample-000167.mp3    male  indian  twenties\n",
      "214  cv-valid-train/sample-000214.mp3  female  indian   fifties\n",
      "242  cv-valid-train/sample-000242.mp3  female  indian  twenties\n",
      "285  cv-valid-train/sample-000285.mp3    male  indian  twenties\n",
      "345  cv-valid-train/sample-000345.mp3    male  indian  twenties\n",
      "477  cv-valid-train/sample-000477.mp3    male  indian  twenties\n",
      "539  cv-valid-train/sample-000539.mp3    male  indian  thirties\n",
      "547  cv-valid-train/sample-000547.mp3    male  indian  twenties\n",
      "563  cv-valid-train/sample-000563.mp3  female  indian   fifties\n",
      "597  cv-valid-train/sample-000597.mp3  female  indian  thirties\n",
      "610  cv-valid-train/sample-000610.mp3    male  indian  thirties\n",
      "671  cv-valid-train/sample-000671.mp3    male  indian  twenties\n",
      "695  cv-valid-train/sample-000695.mp3    male  indian  thirties\n",
      "777  cv-valid-train/sample-000777.mp3    male  indian     teens\n",
      "784  cv-valid-train/sample-000784.mp3  female  indian   fifties\n",
      "801  cv-valid-train/sample-000801.mp3    male  indian  twenties\n",
      "851  cv-valid-train/sample-000851.mp3  female  indian  twenties\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import librosa\n",
    "\n",
    "BASE_DIR = '/Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/'\n",
    "RAW_DATA_DIR = os.path.join(BASE_DIR, 'raw_data')\n",
    "TRAIN_CSV_PATH = os.path.join(RAW_DATA_DIR, 'cv-valid-train.csv')\n",
    "\n",
    "# 관심 액센트 및 기타 조건 (예시)\n",
    "accents = ['indian']\n",
    "# accents = ['canada', 'england', 'indian', 'australia']\n",
    "\n",
    "# CSV 로드 및 기본 필터링 (gender, accent 존재 여부, 관심 액센트, 존재하는 경로 체크)\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "df_train = df_train.dropna(subset=['gender', 'accent'])\n",
    "df_train = df_train[df_train['accent'].isin(accents)]\n",
    "# 이미 파일 존재 여부 체크 (파일 경로 기준)\n",
    "df_train = df_train[df_train['filename'].apply(lambda x: os.path.exists(os.path.join(RAW_DATA_DIR, x)))]\n",
    "df_train = df_train[['filename', 'gender', 'accent', 'age']].copy()\n",
    "\n",
    "print(df_train.head(20))\n",
    "# print(\"초기 CSV의 파일 존재 filtered accent counts:\")\n",
    "# print(df_train['accent'].value_counts())\n",
    "\n",
    "# # --- 손상된 오디오 파일(유효하지 않은 파일) 확인 및 삭제 ---\n",
    "# def is_audio_file_valid(file_path):\n",
    "#     try:\n",
    "#         # sr=None: 원본 샘플링 레이트로 로드 (불필요한 리샘플링 방지)\n",
    "#         audio, sr = librosa.load(file_path, sr=None)\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         return False\n",
    "\n",
    "# # 손상된 파일 목록 수집\n",
    "# invalid_files = []\n",
    "# for idx, row in df_train.iterrows():\n",
    "#     fpath = os.path.join(RAW_DATA_DIR, row['filename'])\n",
    "#     if not is_audio_file_valid(fpath):\n",
    "#         invalid_files.append(row['filename'])\n",
    "\n",
    "# print(f\"손상된(유효하지 않은) 파일 수: {len(invalid_files)}\")\n",
    "\n",
    "# # CSV에서 손상된 파일 제거\n",
    "# df_train_clean = df_train[~df_train['filename'].isin(invalid_files)].copy()\n",
    "\n",
    "# # 실제 디스크에서도 손상된 파일 삭제 (원한다면 실행)\n",
    "# for filename in invalid_files:\n",
    "#     fpath = os.path.join(RAW_DATA_DIR, filename)\n",
    "#     try:\n",
    "#         os.remove(fpath)\n",
    "#         print(f\"삭제 완료: {fpath}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"{fpath} 삭제 실패: {str(e)}\")\n",
    "\n",
    "# print(\"\\n최종 CSV (손상 파일 제거 후) accent counts:\")\n",
    "# print(df_train_clean['accent'].value_counts())\n",
    "\n",
    "# # df_train_clean을 이후의 파이프라인으로 사용하시면 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File-existence filtered accent counts:\n",
      "accent\n",
      "england     14648\n",
      "indian       4382\n",
      "canada       3835\n",
      "scotland     1541\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ACCENTS_OF_INTEREST = ['canada', 'england', 'indian', 'scotland']\n",
    "BASE_DIR = '/Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/'\n",
    "RAW_DATA_DIR = os.path.join(BASE_DIR, 'raw_data')\n",
    "\n",
    "# CSV 로드 및 기본 필터링\n",
    "TRAIN_CSV_PATH = os.path.join(RAW_DATA_DIR, 'cv-valid-train.csv')\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "df_train = df_train.dropna(subset=['gender', 'accent'])\n",
    "df_train = df_train[df_train['accent'].isin(ACCENTS_OF_INTEREST)]\n",
    "df_train = df_train[df_train['filename'].apply(lambda x: os.path.exists(os.path.join(RAW_DATA_DIR, x)))]\n",
    "df_train = df_train[['filename', 'gender', 'accent', 'age']].copy()\n",
    "\n",
    "print(\"File-existence filtered accent counts:\")\n",
    "print(df_train['accent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File-existence filtered accent counts for test set:\n",
      "accent\n",
      "england     298\n",
      "canada      102\n",
      "indian       90\n",
      "scotland     31\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# === df_test ===\n",
    "TEST_CSV_PATH = os.path.join(RAW_DATA_DIR, 'cv-valid-test.csv')\n",
    "\n",
    "df_test = pd.read_csv(TEST_CSV_PATH)\n",
    "\n",
    "# Drop rows with missing gender\n",
    "df_test = df_test.dropna(subset=['gender'])\n",
    "\n",
    "# Filter accents of interest\n",
    "df_test = df_test[df_test['accent'].isin(ACCENTS_OF_INTEREST)]\n",
    "\n",
    "# Drop rows with missing accent\n",
    "df_test = df_test.dropna(subset=['accent'])\n",
    "\n",
    "# Check if each file exists in RAW_DATA_DIR and remove rows where file is missing\n",
    "df_test = df_test[df_test['filename'].apply(lambda x: os.path.exists(os.path.join(RAW_DATA_DIR, x)))]\n",
    "\n",
    "df_test = df_test[['filename', 'gender', 'accent', 'age']]\n",
    "\n",
    "print(\"File-existence filtered accent counts for test set:\")\n",
    "print(df_test['accent'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resample factor information saved to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/train_dataset_info.txt\n",
      "\n",
      "Weighted sample totals per accent (should be equal):\n",
      "accent\n",
      "canada      1033\n",
      "england     1033\n",
      "indian      1033\n",
      "scotland    1033\n",
      "Name: resample_factor, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "MAX_AUG = 1.5   # 최대 augmentation 배수 (예: 최대 2배)\n",
    "\n",
    "# 원본 dataframe 복사 (밸런싱에 사용할 임시 복사본)\n",
    "df_temp = df_train.copy()\n",
    "\n",
    "# (gender, age)별로 모든 accent가 나타나는 조합 선택\n",
    "combo_counts = df_temp.groupby(['gender', 'age'])['accent'].nunique()\n",
    "num_accents = df_temp['accent'].nunique()\n",
    "valid_combos = combo_counts[combo_counts == num_accents].index.tolist()\n",
    "\n",
    "# 새 balanced 그룹 저장용 리스트\n",
    "balanced_dfs = []\n",
    "resample_info_lines = []\n",
    "\n",
    "# 각 (gender, age) 조합별로 처리\n",
    "for gender, age in valid_combos:\n",
    "    subset = df_temp[(df_temp['gender'] == gender) & (df_temp['age'] == age)]\n",
    "    accent_counts = subset.groupby('accent').size()\n",
    "    # 목표 T: 최소 그룹 수의 최대 MAX_AUG 배와, 해당 조합 내 가장 많은 그룹 수 중 작은 값\n",
    "    T = min(accent_counts.max(), int(MAX_AUG * accent_counts.min()))\n",
    "    \n",
    "    for accent_val, group in subset.groupby('accent'):\n",
    "        current_count = len(group)\n",
    "        if current_count > T:\n",
    "            # undersample: T개의 행만 선택, 각 행의 factor = 1\n",
    "            balanced_group = group.sample(n=T, random_state=42)\n",
    "            balanced_group['resample_factor'] = 1\n",
    "            method = \"undersample\"\n",
    "            float_factor = current_count / T  # 참고용\n",
    "        elif current_count == T:\n",
    "            balanced_group = group.copy()\n",
    "            balanced_group['resample_factor'] = 1\n",
    "            method = \"balanced\"\n",
    "            float_factor = 1.0\n",
    "        else:\n",
    "            # oversample (augmentation)\n",
    "            float_factor = T / current_count  # 예: 2.8\n",
    "            int_part = int(float_factor)       # 예: 2\n",
    "            frac_part = float_factor - int_part  # 예: 0.8\n",
    "            balanced_group = group.copy()\n",
    "            balanced_group['resample_factor'] = int_part  # 우선 모든 행에 int_part 할당\n",
    "            partial_count = int(round(current_count * frac_part))\n",
    "            if partial_count > 0 and partial_count <= current_count:\n",
    "                idx_partial = np.random.choice(balanced_group.index, size=partial_count, replace=False)\n",
    "                balanced_group.loc[idx_partial, 'resample_factor'] = int_part + 1\n",
    "            method = f\"oversample (float_factor={float_factor:.2f})\"\n",
    "        \n",
    "        info_line = (f\"Gender={gender}, Age={age}, Accent={accent_val}, \"\n",
    "                     f\"Original={current_count}, T={T}, Final avg factor={balanced_group['resample_factor'].mean():.2f} ({method})\")\n",
    "        resample_info_lines.append(info_line)\n",
    "        balanced_dfs.append(balanced_group)\n",
    "\n",
    "# 최종 balanced DataFrame\n",
    "df_balanced_final = pd.concat(balanced_dfs, ignore_index=True)\n",
    "\n",
    "# 결과 정보를 파일로 저장\n",
    "output_dir = os.path.join(BASE_DIR, \"data\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "info_txt_path = os.path.join(output_dir, \"train_dataset_info.txt\")\n",
    "with open(info_txt_path, \"w\") as f:\n",
    "    f.write(\"Resample Factor Information:\\n\")\n",
    "    for line in resample_info_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "print(\"Resample factor information saved to\", info_txt_path)\n",
    "\n",
    "# 최종 weighted sample 수 계산: 각 accent별 resample_factor의 합\n",
    "weighted_totals = df_balanced_final.groupby('accent')['resample_factor'].sum()\n",
    "print(\"\\nWeighted sample totals per accent (should be equal):\")\n",
    "print(weighted_totals)\n",
    "\n",
    "# # CSV로 저장 (최종 balanced CSV)\n",
    "# aug_csv_path = os.path.join(output_dir, \"df_train_balanced_with_aug.csv\")\n",
    "# df_balanced_final.to_csv(aug_csv_path, index=False)\n",
    "# print(\"\\nBalanced CSV with augmentation factors saved to\", aug_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples per accent (weighted by resample_factor):\n",
      "accent\n",
      "canada      1033\n",
      "england     1033\n",
      "indian      1033\n",
      "scotland    1033\n",
      "Name: resample_factor, dtype: int64\n",
      "\n",
      "Average augmentation factor per accent:\n",
      "accent\n",
      "canada      1.004864\n",
      "england     1.000000\n",
      "indian      1.212441\n",
      "scotland    1.394062\n",
      "Name: resample_factor, dtype: float64\n",
      "\n",
      "Weighted Balanced Accent x Age Confusion Matrix (using resample factors):\n",
      "age       fifties  fourties  sixties  teens  thirties  twenties\n",
      "accent                                                         \n",
      "canada         74        67       73     37       535       247\n",
      "england        74        67       73     37       535       247\n",
      "indian         74        67       73     37       535       247\n",
      "scotland       74        67       73     37       535       247\n",
      "\n",
      "Weighted Balanced Accent x Gender Confusion Matrix (using resample factors):\n",
      "gender    female  male\n",
      "accent                \n",
      "canada        92   941\n",
      "england       92   941\n",
      "indian        92   941\n",
      "scotland      92   941\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# CSV 불러오기\n",
    "df_balanced = df_balanced_final.copy()\n",
    "\n",
    "# 각 accent에 대해 resample_factor 값의 합계를 계산하면, augmentation 적용 후 총 샘플 수가 됩니다.\n",
    "accent_totals = df_balanced.groupby('accent')['resample_factor'].sum()\n",
    "print(\"\\nTotal samples per accent (weighted by resample_factor):\")\n",
    "print(accent_totals)\n",
    "\n",
    "# 각 그룹의 augmentation factor 평균 확인 (예: 목표 oversample 배수)\n",
    "avg_factor = df_balanced.groupby('accent')['resample_factor'].mean()\n",
    "print(\"\\nAverage augmentation factor per accent:\")\n",
    "print(avg_factor)\n",
    "\n",
    "# Weighted confusion matrix by augmentation factor (Accent x Age)\n",
    "weighted_confusion_age = pd.pivot_table(\n",
    "    df_balanced, \n",
    "    index='accent', \n",
    "    columns='age', \n",
    "    values='resample_factor', \n",
    "    aggfunc='sum', \n",
    "    fill_value=0\n",
    ")\n",
    "print(\"\\nWeighted Balanced Accent x Age Confusion Matrix (using resample factors):\")\n",
    "print(weighted_confusion_age)\n",
    "\n",
    "# Weighted confusion matrix by augmentation factor (Accent x Gender)\n",
    "weighted_confusion_gender = pd.pivot_table(\n",
    "    df_balanced, \n",
    "    index='accent', \n",
    "    columns='gender', \n",
    "    values='resample_factor', \n",
    "    aggfunc='sum', \n",
    "    fill_value=0\n",
    ")\n",
    "print(\"\\nWeighted Balanced Accent x Gender Confusion Matrix (using resample factors):\")\n",
    "print(weighted_confusion_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accent counts in validation set:\n",
      "accent\n",
      "canada      500\n",
      "england     500\n",
      "indian      500\n",
      "scotland    500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# cv-other-train.csv 파일에서 validation candidate 데이터 읽기\n",
    "VALID_CSV_PATH = os.path.join(RAW_DATA_DIR, 'cv-other-train.csv')\n",
    "df_valid_candidate = pd.read_csv(VALID_CSV_PATH)\n",
    "\n",
    "# training set과 동일한 filtering 적용\n",
    "df_valid_candidate = df_valid_candidate.dropna(subset=['gender', 'accent'])\n",
    "df_valid_candidate = df_valid_candidate[df_valid_candidate['accent'].isin(ACCENTS_OF_INTEREST)]\n",
    "df_valid_candidate = df_valid_candidate[\n",
    "    df_valid_candidate['filename'].apply(lambda x: os.path.exists(os.path.join(RAW_DATA_DIR, x)))\n",
    "]\n",
    "df_valid_candidate = df_valid_candidate[['filename', 'gender', 'accent', 'age']].copy()\n",
    "\n",
    "# 각 악센트별로 최대 500개 샘플 추출 (해당 악센트 그룹에 500개 미만이면 전체 사용)\n",
    "balanced_valid_groups = []\n",
    "for accent, group in df_valid_candidate.groupby('accent'):\n",
    "    n_samples = 500 if len(group) >= 500 else len(group)\n",
    "    sampled_group = group.sample(n=n_samples, random_state=42)\n",
    "    balanced_valid_groups.append(sampled_group)\n",
    "\n",
    "# 균형 잡힌 validation DataFrame 생성\n",
    "df_valid = pd.concat(balanced_valid_groups, ignore_index=True)\n",
    "\n",
    "# 각 악센트별 샘플 수 출력\n",
    "accent_counts = df_valid['accent'].value_counts()\n",
    "print(\"Accent counts in validation set:\")\n",
    "print(accent_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset accent counts:\n",
      "accent_encoded\n",
      "1    1033\n",
      "0    1028\n",
      "2     852\n",
      "3     741\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation dataset accent counts:\n",
      "accent_encoded\n",
      "0    500\n",
      "1    500\n",
      "2    500\n",
      "3    500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label classes:\n",
      "['canada' 'england' 'indian' 'scotland']\n",
      "Accent label mapping appended to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/label_mapping_info.txt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# Create a label encoder and fit on the 'accent' column of df_balanced\n",
    "label_encoder = LabelEncoder()\n",
    "df_balanced['accent_encoded'] = label_encoder.fit_transform(df_balanced['accent'])\n",
    "\n",
    "# Use the same label encoder to transform the 'accent' column of df_valid\n",
    "df_valid['accent_encoded'] = label_encoder.transform(df_valid['accent'])\n",
    "\n",
    "df_test['accent_encoded'] = label_encoder.transform(df_test['accent'])\n",
    "\n",
    "# Print counts for verification\n",
    "print(\"Balanced dataset accent counts:\")\n",
    "print(df_balanced['accent_encoded'].value_counts())\n",
    "print(\"\\nValidation dataset accent counts:\")\n",
    "print(df_valid['accent_encoded'].value_counts())\n",
    "print(\"\\nLabel classes:\")\n",
    "print(label_encoder.classes_)\n",
    "\n",
    "# Append the accent label mapping information to the existing info text file\n",
    "txt_out_path = os.path.join(BASE_DIR, 'data', 'label_mapping_info.txt')\n",
    "with open(txt_out_path, \"a\") as f:  # open in append mode\n",
    "    f.write(\"\\nAccent Label Mapping:\\n\")\n",
    "    for encoded_value, accent in enumerate(label_encoder.classes_):\n",
    "        f.write(f\"{encoded_value}: {accent}\\n\")\n",
    "\n",
    "print(\"Accent label mapping appended to\", txt_out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced validation DataFrame saved to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/df_valid.csv\n",
      "Balanced DataFrame saved to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/df_train_balanced.csv\n",
      "Test DataFrame saved to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/df_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the balanced validation DataFrame to a CSV file\n",
    "df_valid_csv_path = os.path.join(output_dir, 'df_valid.csv')\n",
    "df_valid.to_csv(df_valid_csv_path, index=False)\n",
    "print(\"Balanced validation DataFrame saved to\", df_valid_csv_path)\n",
    "\n",
    "# Save the balanced DataFrame to a CSV file in the same directory\n",
    "df_balanced_csv_path = os.path.join(output_dir, 'df_train_balanced.csv')\n",
    "df_balanced.to_csv(df_balanced_csv_path, index=False)\n",
    "print(\"Balanced DataFrame saved to\", df_balanced_csv_path)\n",
    "\n",
    "# Save the df_test DataFrame to a CSV file\n",
    "output_dir = os.path.join(BASE_DIR, 'data')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "df_test_csv_path = os.path.join(output_dir, 'df_test.csv')\n",
    "df_test.to_csv(df_test_csv_path, index=False)\n",
    "print(\"Test DataFrame saved to\", df_test_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed df_balance, df_valid, and df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def lowpass_filter(data, sr, cutoff=5000, order=5):\n",
    "    nyquist = 0.5 * sr\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return lfilter(b, a, data)\n",
    "\n",
    "def augment_audio(audio, sr):\n",
    "    \"\"\"\n",
    "    Return a list of augmented audio signals using different augmentation techniques.\n",
    "    Augmentation techniques include:\n",
    "      - Pitch shift: random semitone shift between -2 and 2\n",
    "      - Time stretch: random rate between 0.9 and 1.1\n",
    "      - Noise addition: add small random Gaussian noise\n",
    "    \"\"\"\n",
    "    augmented_audios = []\n",
    "    \n",
    "    # Pitch shift\n",
    "    try:\n",
    "        semitones = np.random.uniform(-2, 2)\n",
    "        pitch_shifted = librosa.effects.pitch_shift(y=audio, sr=sr, n_steps=semitones)\n",
    "        augmented_audios.append(pitch_shifted)\n",
    "    except Exception as e:\n",
    "        print(\"Pitch shift error:\", e)\n",
    "    \n",
    "    # Time stretch\n",
    "    try:\n",
    "        rate = np.random.uniform(0.75, 1.25)\n",
    "        time_stretched = librosa.effects.time_stretch(y=audio, rate=rate)\n",
    "        augmented_audios.append(time_stretched)\n",
    "    except Exception as e:\n",
    "        print(\"Time stretch error:\", e)\n",
    "    \n",
    "    # Noise addition\n",
    "    try:\n",
    "        noise = np.random.randn(len(audio)) * 0.005  # Adjust noise level as needed\n",
    "        noisy = audio + noise\n",
    "        augmented_audios.append(noisy)\n",
    "    except Exception as e:\n",
    "        print(\"Noise addition error:\", e)\n",
    "    \n",
    "    return augmented_audios\n",
    "\n",
    "\n",
    "def extract_features_with_augmentation(file_path, h=12, aug_count=0):\n",
    "    \"\"\"\n",
    "    Load an audio file, filter, and extract original MFCCs.\n",
    "    Then generate 'aug_count' augmented versions and extract MFCCs for each.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "        audio = np.ravel(audio)  # ensure 1D\n",
    "        audio_filt = lowpass_filter(audio, sr, cutoff=5000)\n",
    "        \n",
    "        win_length = int(0.025 * sr)\n",
    "        hop_length = int(0.01 * sr)\n",
    "        n_fft = win_length\n",
    "        \n",
    "        # original MFCC\n",
    "        mfcc_orig = librosa.feature.mfcc(\n",
    "            y=audio_filt,\n",
    "            sr=sr,\n",
    "            n_mfcc=h,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            win_length=win_length,\n",
    "            window='hann'\n",
    "        )\n",
    "        outputs = [mfcc_orig]\n",
    "        \n",
    "        if aug_count > 0:\n",
    "            aug_audios = augment_audio(audio_filt, sr)\n",
    "            for i in range(aug_count):\n",
    "                if aug_audios:\n",
    "                    # pick one augmented version from the list\n",
    "                    aug_audio = random.choice(aug_audios)\n",
    "                    aug_audio = np.ravel(aug_audio)  # ensure 1D\n",
    "                    mfcc_aug = librosa.feature.mfcc(\n",
    "                        y=aug_audio,\n",
    "                        sr=sr,\n",
    "                        n_mfcc=h,\n",
    "                        n_fft=n_fft,\n",
    "                        hop_length=hop_length,\n",
    "                        win_length=win_length,\n",
    "                        window='hann'\n",
    "                    )\n",
    "                    outputs.append(mfcc_aug)\n",
    "        return outputs\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def pad_or_truncate(feature_matrix, target_length):\n",
    "    current_length = feature_matrix.shape[1]\n",
    "    if current_length < target_length:\n",
    "        return np.pad(feature_matrix, ((0, 0), (0, target_length - current_length)), mode='constant')\n",
    "    else:\n",
    "        return feature_matrix[:, :target_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MFCC features and applying augmentation for training set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train features: 100%|██████████| 3654/3654 [02:54<00:00, 20.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MFCC features for validation set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid features: 100%|██████████| 2000/2000 [00:43<00:00, 45.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MFCC features for test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test features: 100%|██████████| 521/521 [00:11<00:00, 44.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2273"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Process Training Data with Augmentation ---\n",
    "all_mfccs_train = []  # Augmented MFCC list (augmented samples will be added)\n",
    "print(\"Extracting MFCC features and applying augmentation for training set:\")\n",
    "\n",
    "for idx, row in tqdm(df_balanced.iterrows(), total=len(df_balanced), desc=\"Train features\"):\n",
    "    file_path = os.path.join(RAW_DATA_DIR, row['filename'])\n",
    "    # resample_factor를 읽습니다.\n",
    "    try:\n",
    "        factor = float(row.get('resample_factor', 1))\n",
    "    except:\n",
    "        factor = 1.0\n",
    "    # 추가로 생성할 augmentation sample 수 = round(factor) - 1, (만약 음수가 나오면 0)\n",
    "    aug_count = max(0, int(round(factor)) - 1)\n",
    "    \n",
    "    mfcc_list = extract_features_with_augmentation(file_path, h=12, aug_count=aug_count)\n",
    "    # mfcc_list는 원본 + 추가 augmented MFCC들을 담은 리스트입니다.\n",
    "    # 각 MFCC의 shape는 (h, time_frames)\n",
    "    # 모든 MFCC sample들을 모두 추가합니다.\n",
    "    all_mfccs_train.extend(mfcc_list)\n",
    "\n",
    "# --- Process Validation Data (원본만 사용) ---\n",
    "all_mfccs_valid = []\n",
    "print(\"Extracting MFCC features for validation set:\")\n",
    "for idx, row in tqdm(df_valid.iterrows(), total=len(df_valid), desc=\"Valid features\"):\n",
    "    file_path = os.path.join(RAW_DATA_DIR, row['filename'])\n",
    "    mfcc = extract_features_with_augmentation(file_path, h=12, aug_count=0)\n",
    "    if mfcc is not None:\n",
    "        all_mfccs_valid.append(mfcc)\n",
    "\n",
    "# --- Process Test Data (원본만 사용) ---\n",
    "all_mfccs_test = []\n",
    "print(\"Extracting MFCC features for test set:\")\n",
    "for idx, row in tqdm(df_test.iterrows(), total=len(df_test), desc=\"Test features\"):\n",
    "    file_path = os.path.join(RAW_DATA_DIR, row['filename'])\n",
    "    mfcc = extract_features_with_augmentation(file_path, h=12, aug_count=0)\n",
    "    if mfcc is not None:\n",
    "        all_mfccs_test.append(mfcc)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median time frames (train augmented): 382\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Build y_train using the augmentation_counts; df_balanced should have the 'accent_encoded' column\u001b[39;00m\n\u001b[32m     56\u001b[39m y_train_rep = build_labels(df_balanced, augmentation_counts)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m y_train = \u001b[43mto_categorical\u001b[49m(y_train_rep)\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# For validation and test sets, assume the labels are taken directly from df_valid and df_test respectively.\u001b[39;00m\n\u001b[32m     60\u001b[39m y_valid_rep = df_valid[\u001b[33m'\u001b[39m\u001b[33maccent_encoded\u001b[39m\u001b[33m'\u001b[39m].values\n",
      "\u001b[31mNameError\u001b[39m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Helper function to flatten nested lists of MFCC arrays ---\n",
    "def flatten_mfcc_list(mfcc_list):\n",
    "    flat_list = []\n",
    "    for item in mfcc_list:\n",
    "        # If the item is a list, extend with its contents; else append the item itself\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(item)\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "# --- Flatten the validation and test MFCC lists ---\n",
    "all_mfccs_valid_flat = flatten_mfcc_list(all_mfccs_valid)\n",
    "all_mfccs_test_flat = flatten_mfcc_list(all_mfccs_test)\n",
    "\n",
    "# --- Determine a common target length for MFCC time frames ---\n",
    "# We use the training set augmented samples only.\n",
    "all_lengths_train = [m.shape[1] for m in all_mfccs_train if m is not None]\n",
    "median_time_frames = int(np.median(all_lengths_train))\n",
    "print(\"Median time frames (train augmented):\", median_time_frames)\n",
    "\n",
    "# --- Pad or truncate each MFCC matrix to the median_time_frames ---\n",
    "padded_mfccs_train = [pad_or_truncate(m, median_time_frames) for m in all_mfccs_train if m is not None]\n",
    "padded_mfccs_valid = [pad_or_truncate(m, median_time_frames) for m in all_mfccs_valid_flat if m is not None]\n",
    "padded_mfccs_test  = [pad_or_truncate(m, median_time_frames) for m in all_mfccs_test_flat if m is not None]\n",
    "\n",
    "# --- Build the final training audio array ---\n",
    "# Each MFCC sample is expanded to shape (1, h, median_time_frames)\n",
    "X_audio_train = np.stack([np.expand_dims(m, axis=0) for m in padded_mfccs_train])\n",
    "X_audio_valid = np.stack([np.expand_dims(m, axis=0) for m in padded_mfccs_valid])\n",
    "X_audio_test  = np.stack([np.expand_dims(m, axis=0) for m in padded_mfccs_test])\n",
    "\n",
    "# --- Build training labels considering augmentation counts ---\n",
    "def build_labels(df, augmentation_counts):\n",
    "    \"\"\"\n",
    "    Given a DataFrame and augmentation_counts (a list of total samples per original row),\n",
    "    replicate the row's label accordingly.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for idx, row in df.iterrows():\n",
    "        count = augmentation_counts[idx]\n",
    "        labels.extend([row['accent_encoded']] * count)\n",
    "    return np.array(labels)\n",
    "\n",
    "# Create augmentation_counts list: for each row in df_balanced, the total samples generated = round(factor)\n",
    "augmentation_counts = []\n",
    "for idx, row in df_balanced.iterrows():\n",
    "    try:\n",
    "        factor = float(row.get('resample_factor', 1))\n",
    "    except:\n",
    "        factor = 1.0\n",
    "    total = int(round(factor))\n",
    "    augmentation_counts.append(total)\n",
    "\n",
    "# Build y_train using the augmentation_counts; df_balanced should have the 'accent_encoded' column\n",
    "y_train_rep = build_labels(df_balanced, augmentation_counts)\n",
    "y_train = to_categorical(y_train_rep)\n",
    "\n",
    "# For validation and test sets, assume the labels are taken directly from df_valid and df_test respectively.\n",
    "y_valid_rep = df_valid['accent_encoded'].values\n",
    "y_valid = to_categorical(y_valid_rep)\n",
    "y_test_rep = df_test['accent_encoded'].values\n",
    "y_test = to_categorical(y_test_rep)\n",
    "\n",
    "print(\"Final training audio shape (with augmentation):\", X_audio_train.shape)\n",
    "print(\"Final training label shape:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation dataset to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/valid-dataset.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Save the NPZ files ---\n",
    "output_dir = os.path.join(BASE_DIR, \"data\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "train_npz_path = os.path.join(output_dir, \"train-dataset.npz\")\n",
    "np.savez_compressed(train_npz_path, X=X_audio_train, y=y_train)\n",
    "print(\"Saved training dataset to\", train_npz_path)\n",
    "\n",
    "valid_npz_path = os.path.join(output_dir, \"valid-dataset.npz\")\n",
    "np.savez_compressed(valid_npz_path, X=X_audio_valid, y=y_valid)\n",
    "print(\"Saved validation dataset to\", valid_npz_path)\n",
    "\n",
    "test_npz_path = os.path.join(output_dir, \"test-dataset.npz\")\n",
    "np.savez_compressed(test_npz_path, X=X_audio_test, y=y_test)\n",
    "print(\"Saved test dataset to\", test_npz_path)\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
