{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import librosa\n",
    "\n",
    "# BASE_DIR = '/Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/'\n",
    "# RAW_DATA_DIR = os.path.join(BASE_DIR, 'raw_data')\n",
    "# TRAIN_CSV_PATH = os.path.join(RAW_DATA_DIR, 'cv-valid-train.csv')\n",
    "\n",
    "# # 관심 액센트 및 기타 조건 (예시)\n",
    "# accents = ['canada', 'england', 'indian', 'australia']\n",
    "\n",
    "# # CSV 로드 및 기본 필터링 (gender, accent 존재 여부, 관심 액센트, 존재하는 경로 체크)\n",
    "# df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "# df_train = df_train.dropna(subset=['gender', 'accent'])\n",
    "# df_train = df_train[df_train['accent'].isin(accents)]\n",
    "# # 이미 파일 존재 여부 체크 (파일 경로 기준)\n",
    "# df_train = df_train[df_train['filename'].apply(lambda x: os.path.exists(os.path.join(RAW_DATA_DIR, x)))]\n",
    "# df_train = df_train[['filename', 'gender', 'accent', 'age']].copy()\n",
    "\n",
    "# print(\"초기 CSV의 파일 존재 filtered accent counts:\")\n",
    "# print(df_train['accent'].value_counts())\n",
    "\n",
    "# # --- 손상된 오디오 파일(유효하지 않은 파일) 확인 및 삭제 ---\n",
    "# def is_audio_file_valid(file_path):\n",
    "#     try:\n",
    "#         # sr=None: 원본 샘플링 레이트로 로드 (불필요한 리샘플링 방지)\n",
    "#         audio, sr = librosa.load(file_path, sr=None)\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         return False\n",
    "\n",
    "# # 손상된 파일 목록 수집\n",
    "# invalid_files = []\n",
    "# for idx, row in df_train.iterrows():\n",
    "#     fpath = os.path.join(RAW_DATA_DIR, row['filename'])\n",
    "#     if not is_audio_file_valid(fpath):\n",
    "#         invalid_files.append(row['filename'])\n",
    "\n",
    "# print(f\"손상된(유효하지 않은) 파일 수: {len(invalid_files)}\")\n",
    "\n",
    "# # CSV에서 손상된 파일 제거\n",
    "# df_train_clean = df_train[~df_train['filename'].isin(invalid_files)].copy()\n",
    "\n",
    "# # 실제 디스크에서도 손상된 파일 삭제 (원한다면 실행)\n",
    "# for filename in invalid_files:\n",
    "#     fpath = os.path.join(RAW_DATA_DIR, filename)\n",
    "#     try:\n",
    "#         os.remove(fpath)\n",
    "#         print(f\"삭제 완료: {fpath}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"{fpath} 삭제 실패: {str(e)}\")\n",
    "\n",
    "# print(\"\\n최종 CSV (손상 파일 제거 후) accent counts:\")\n",
    "# print(df_train_clean['accent'].value_counts())\n",
    "\n",
    "# # df_train_clean을 이후의 파이프라인으로 사용하시면 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File-existence filtered accent counts:\n",
      "accent\n",
      "england     14619\n",
      "indian       4372\n",
      "canada       3706\n",
      "scotland     1541\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "ACCENTS_OF_INTEREST = ['canada', 'england', 'indian', 'scotland']\n",
    "BASE_DIR = '/Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/'\n",
    "RAW_DATA_DIR = os.path.join(BASE_DIR, 'raw_data')\n",
    "\n",
    "TRAIN_CSV_PATH = os.path.join(RAW_DATA_DIR, 'cv-valid-train.csv')\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "\n",
    "# gender, accent, age 중 하나라도 NA인 행 삭제\n",
    "df_train = df_train.dropna(subset=['gender', 'accent', 'age'])\n",
    "\n",
    "# 관심 악센트로 필터링\n",
    "df_train = df_train[df_train['accent'].isin(ACCENTS_OF_INTEREST)]\n",
    "\n",
    "# 파일이 존재하는지 확인하여 필터링\n",
    "df_train = df_train[df_train['filename'].apply(lambda x: os.path.exists(os.path.join(RAW_DATA_DIR, x)))]\n",
    "\n",
    "# 필요한 컬럼만 남기고 복사\n",
    "df_train = df_train[['filename', 'gender', 'accent', 'age']].copy()\n",
    "\n",
    "print(\"File-existence filtered accent counts:\")\n",
    "print(df_train['accent'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File-existence filtered accent counts for test set:\n",
      "accent\n",
      "england     298\n",
      "canada       99\n",
      "indian       90\n",
      "scotland     31\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# === df_test ===\n",
    "TEST_CSV_PATH = os.path.join(RAW_DATA_DIR, 'cv-valid-test.csv')\n",
    "df_test = pd.read_csv(TEST_CSV_PATH)\n",
    "\n",
    "# gender, accent, age 컬럼 중 하나라도 결측치가 있으면 삭제\n",
    "df_test = df_test.dropna(subset=['gender', 'accent', 'age'])\n",
    "\n",
    "# 관심 악센트 필터링\n",
    "df_test = df_test[df_test['accent'].isin(ACCENTS_OF_INTEREST)]\n",
    "\n",
    "# 파일 존재 여부 확인 후 필터링\n",
    "df_test = df_test[df_test['filename'].apply(lambda x: os.path.exists(os.path.join(RAW_DATA_DIR, x)))]\n",
    "\n",
    "# 필요한 컬럼만 선택\n",
    "df_test = df_test[['filename', 'gender', 'accent', 'age']]\n",
    "\n",
    "print(\"File-existence filtered accent counts for test set:\")\n",
    "print(df_test['accent'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resample factor information saved to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/train_dataset_info.txt\n",
      "\n",
      "Weighted sample totals per accent (should be equal):\n",
      "accent\n",
      "canada      2073\n",
      "england     2073\n",
      "indian      2073\n",
      "scotland    2073\n",
      "Name: resample_factor, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "MAX_AUG = 3   # 최대 augmentation 배수 (예: 최대 2배)\n",
    "\n",
    "# 원본 dataframe 복사 (밸런싱에 사용할 임시 복사본)\n",
    "df_temp = df_train.copy()\n",
    "\n",
    "# (gender, age)별로 모든 accent가 나타나는 조합 선택\n",
    "combo_counts = df_temp.groupby(['gender', 'age'])['accent'].nunique()\n",
    "num_accents = df_temp['accent'].nunique()\n",
    "valid_combos = combo_counts[combo_counts == num_accents].index.tolist()\n",
    "\n",
    "# 새 balanced 그룹 저장용 리스트\n",
    "balanced_dfs = []\n",
    "resample_info_lines = []\n",
    "\n",
    "# 각 (gender, age) 조합별로 처리\n",
    "for gender, age in valid_combos:\n",
    "    subset = df_temp[(df_temp['gender'] == gender) & (df_temp['age'] == age)]\n",
    "    accent_counts = subset.groupby('accent').size()\n",
    "    # 목표 T: 최소 그룹 수의 최대 MAX_AUG 배와, 해당 조합 내 가장 많은 그룹 수 중 작은 값\n",
    "    T = min(accent_counts.max(), int(MAX_AUG * accent_counts.min()))\n",
    "    \n",
    "    for accent_val, group in subset.groupby('accent'):\n",
    "        current_count = len(group)\n",
    "        if current_count > T:\n",
    "            # undersample: T개의 행만 선택, 각 행의 factor = 1\n",
    "            balanced_group = group.sample(n=T, random_state=42)\n",
    "            balanced_group['resample_factor'] = 1\n",
    "            method = \"undersample\"\n",
    "            float_factor = current_count / T  # 참고용\n",
    "        elif current_count == T:\n",
    "            balanced_group = group.copy()\n",
    "            balanced_group['resample_factor'] = 1\n",
    "            method = \"balanced\"\n",
    "            float_factor = 1.0\n",
    "        else:\n",
    "            # oversample (augmentation)\n",
    "            float_factor = T / current_count  # 예: 2.8\n",
    "            int_part = int(float_factor)       # 예: 2\n",
    "            frac_part = float_factor - int_part  # 예: 0.8\n",
    "            balanced_group = group.copy()\n",
    "            balanced_group['resample_factor'] = int_part  # 우선 모든 행에 int_part 할당\n",
    "            partial_count = int(round(current_count * frac_part))\n",
    "            if partial_count > 0 and partial_count <= current_count:\n",
    "                idx_partial = np.random.choice(balanced_group.index, size=partial_count, replace=False)\n",
    "                balanced_group.loc[idx_partial, 'resample_factor'] = int_part + 1\n",
    "            method = f\"oversample (float_factor={float_factor:.2f})\"\n",
    "        \n",
    "        info_line = (f\"Gender={gender}, Age={age}, Accent={accent_val}, \"\n",
    "                     f\"Original={current_count}, T={T}, Final avg factor={balanced_group['resample_factor'].mean():.2f} ({method})\")\n",
    "        resample_info_lines.append(info_line)\n",
    "        balanced_dfs.append(balanced_group)\n",
    "\n",
    "# 최종 balanced DataFrame\n",
    "df_balanced_final = pd.concat(balanced_dfs, ignore_index=True)\n",
    "\n",
    "# 결과 정보를 파일로 저장\n",
    "output_dir = os.path.join(BASE_DIR, \"data\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "info_txt_path = os.path.join(output_dir, \"train_dataset_info.txt\")\n",
    "with open(info_txt_path, \"w\") as f:\n",
    "    f.write(\"Resample Factor Information:\\n\")\n",
    "    for line in resample_info_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "print(\"Resample factor information saved to\", info_txt_path)\n",
    "\n",
    "# 최종 weighted sample 수 계산: 각 accent별 resample_factor의 합\n",
    "weighted_totals = df_balanced_final.groupby('accent')['resample_factor'].sum()\n",
    "print(\"\\nWeighted sample totals per accent (should be equal):\")\n",
    "print(weighted_totals)\n",
    "\n",
    "# # CSV로 저장 (최종 balanced CSV)\n",
    "# aug_csv_path = os.path.join(output_dir, \"df_train_balanced_with_aug.csv\")\n",
    "# df_balanced_final.to_csv(aug_csv_path, index=False)\n",
    "# print(\"\\nBalanced CSV with augmentation factors saved to\", aug_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples per accent (weighted by resample_factor):\n",
      "accent\n",
      "canada      2073\n",
      "england     2073\n",
      "indian      2073\n",
      "scotland    2073\n",
      "Name: resample_factor, dtype: int64\n",
      "\n",
      "Average augmentation factor per accent:\n",
      "accent\n",
      "canada      1.353133\n",
      "england     1.000000\n",
      "indian      1.727500\n",
      "scotland    2.311037\n",
      "Name: resample_factor, dtype: float64\n",
      "\n",
      "Weighted Balanced Accent x Age Confusion Matrix (using resample factors):\n",
      "age       fifties  fourties  sixties  teens  thirties  twenties\n",
      "accent                                                         \n",
      "canada        150       135      147     75      1071       495\n",
      "england       150       135      147     75      1071       495\n",
      "indian        150       135      147     75      1071       495\n",
      "scotland      150       135      147     75      1071       495\n",
      "\n",
      "Weighted Balanced Accent x Gender Confusion Matrix (using resample factors):\n",
      "gender    female  male\n",
      "accent                \n",
      "canada       186  1887\n",
      "england      186  1887\n",
      "indian       186  1887\n",
      "scotland     186  1887\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# CSV 불러오기\n",
    "df_balanced = df_balanced_final.copy()\n",
    "\n",
    "# 각 accent에 대해 resample_factor 값의 합계를 계산하면, augmentation 적용 후 총 샘플 수가 됩니다.\n",
    "accent_totals = df_balanced.groupby('accent')['resample_factor'].sum()\n",
    "print(\"\\nTotal samples per accent (weighted by resample_factor):\")\n",
    "print(accent_totals)\n",
    "\n",
    "# 각 그룹의 augmentation factor 평균 확인 (예: 목표 oversample 배수)\n",
    "avg_factor = df_balanced.groupby('accent')['resample_factor'].mean()\n",
    "print(\"\\nAverage augmentation factor per accent:\")\n",
    "print(avg_factor)\n",
    "\n",
    "# Weighted confusion matrix by augmentation factor (Accent x Age)\n",
    "weighted_confusion_age = pd.pivot_table(\n",
    "    df_balanced, \n",
    "    index='accent', \n",
    "    columns='age', \n",
    "    values='resample_factor', \n",
    "    aggfunc='sum', \n",
    "    fill_value=0\n",
    ")\n",
    "print(\"\\nWeighted Balanced Accent x Age Confusion Matrix (using resample factors):\")\n",
    "print(weighted_confusion_age)\n",
    "\n",
    "# Weighted confusion matrix by augmentation factor (Accent x Gender)\n",
    "weighted_confusion_gender = pd.pivot_table(\n",
    "    df_balanced, \n",
    "    index='accent', \n",
    "    columns='gender', \n",
    "    values='resample_factor', \n",
    "    aggfunc='sum', \n",
    "    fill_value=0\n",
    ")\n",
    "print(\"\\nWeighted Balanced Accent x Gender Confusion Matrix (using resample factors):\")\n",
    "print(weighted_confusion_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accent counts in validation set:\n",
      "accent\n",
      "canada      500\n",
      "england     500\n",
      "indian      500\n",
      "scotland    500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# cv-other-train.csv 파일에서 validation candidate 데이터 읽기\n",
    "VALID_CSV_PATH = os.path.join(RAW_DATA_DIR, 'cv-other-train.csv')\n",
    "df_valid_candidate = pd.read_csv(VALID_CSV_PATH)\n",
    "\n",
    "# training set과 동일한 filtering 적용: 'gender', 'accent', 'age' 컬럼에 결측치 제거\n",
    "df_valid_candidate = df_valid_candidate.dropna(subset=['gender', 'accent', 'age'])\n",
    "df_valid_candidate = df_valid_candidate[df_valid_candidate['accent'].isin(ACCENTS_OF_INTEREST)]\n",
    "df_valid_candidate = df_valid_candidate[\n",
    "    df_valid_candidate['filename'].apply(lambda x: os.path.exists(os.path.join(RAW_DATA_DIR, x)))\n",
    "]\n",
    "df_valid_candidate = df_valid_candidate[['filename', 'gender', 'accent', 'age']].copy()\n",
    "\n",
    "# 각 악센트별로 최대 500개 샘플 추출 (500개 미만인 경우 전체 사용)\n",
    "balanced_valid_groups = []\n",
    "for accent, group in df_valid_candidate.groupby('accent'):\n",
    "    n_samples = 500 if len(group) >= 500 else len(group)\n",
    "    sampled_group = group.sample(n=n_samples, random_state=42)\n",
    "    balanced_valid_groups.append(sampled_group)\n",
    "\n",
    "# 균형 잡힌 validation DataFrame 생성\n",
    "df_valid = pd.concat(balanced_valid_groups, ignore_index=True)\n",
    "\n",
    "# 각 악센트별 샘플 수 출력\n",
    "accent_counts = df_valid['accent'].value_counts()\n",
    "print(\"Accent counts in validation set:\")\n",
    "print(accent_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset accent counts:\n",
      "accent_encoded\n",
      "1    2073\n",
      "0    1532\n",
      "2    1200\n",
      "3     897\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation dataset accent counts:\n",
      "accent_encoded\n",
      "0    500\n",
      "1    500\n",
      "2    500\n",
      "3    500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label classes:\n",
      "['canada' 'england' 'indian' 'scotland']\n",
      "Accent label mapping appended to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/label_mapping_info.txt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# Create a label encoder and fit on the 'accent' column of df_balanced\n",
    "label_encoder = LabelEncoder()\n",
    "df_balanced['accent_encoded'] = label_encoder.fit_transform(df_balanced['accent'])\n",
    "\n",
    "# Use the same label encoder to transform the 'accent' column of df_valid\n",
    "df_valid['accent_encoded'] = label_encoder.transform(df_valid['accent'])\n",
    "\n",
    "df_test['accent_encoded'] = label_encoder.transform(df_test['accent'])\n",
    "\n",
    "# Print counts for verification\n",
    "print(\"Balanced dataset accent counts:\")\n",
    "print(df_balanced['accent_encoded'].value_counts())\n",
    "print(\"\\nValidation dataset accent counts:\")\n",
    "print(df_valid['accent_encoded'].value_counts())\n",
    "print(\"\\nLabel classes:\")\n",
    "print(label_encoder.classes_)\n",
    "\n",
    "# Append the accent label mapping information to the existing info text file\n",
    "txt_out_path = os.path.join(BASE_DIR, 'data', 'label_mapping_info.txt')\n",
    "with open(txt_out_path, \"a\") as f:  # open in append mode\n",
    "    f.write(\"\\nAccent Label Mapping:\\n\")\n",
    "    for encoded_value, accent in enumerate(label_encoder.classes_):\n",
    "        f.write(f\"{encoded_value}: {accent}\\n\")\n",
    "\n",
    "print(\"Accent label mapping appended to\", txt_out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced validation DataFrame saved to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/df_valid.csv\n",
      "Balanced DataFrame saved to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/df_train_balanced.csv\n",
      "Test DataFrame saved to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/df_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the balanced validation DataFrame to a CSV file\n",
    "df_valid_csv_path = os.path.join(output_dir, 'df_valid.csv')\n",
    "df_valid.to_csv(df_valid_csv_path, index=False)\n",
    "print(\"Balanced validation DataFrame saved to\", df_valid_csv_path)\n",
    "\n",
    "# Save the balanced DataFrame to a CSV file in the same directory\n",
    "df_balanced_csv_path = os.path.join(output_dir, 'df_train_balanced.csv')\n",
    "df_balanced.to_csv(df_balanced_csv_path, index=False)\n",
    "print(\"Balanced DataFrame saved to\", df_balanced_csv_path)\n",
    "\n",
    "# Save the df_test DataFrame to a CSV file\n",
    "output_dir = os.path.join(BASE_DIR, 'data')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "df_test_csv_path = os.path.join(output_dir, 'df_test.csv')\n",
    "df_test.to_csv(df_test_csv_path, index=False)\n",
    "print(\"Test DataFrame saved to\", df_test_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completed df_balance, df_valid, and df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def lowpass_filter(data, sr, cutoff=5000, order=5):\n",
    "    nyquist = 0.5 * sr\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return lfilter(b, a, data)\n",
    "\n",
    "def augment_audio(audio, sr):\n",
    "    \"\"\"\n",
    "    Return a list of augmented audio signals using different augmentation techniques.\n",
    "    Augmentation techniques include:\n",
    "      - Pitch shift: random semitone shift between -2 and 2\n",
    "      - Time stretch: random rate between 0.9 and 1.1\n",
    "      - Noise addition: add small random Gaussian noise\n",
    "    \"\"\"\n",
    "    augmented_audios = []\n",
    "    \n",
    "    # Pitch shift\n",
    "    try:\n",
    "        semitones = np.random.uniform(-2, 2)\n",
    "        pitch_shifted = librosa.effects.pitch_shift(y=audio, sr=sr, n_steps=semitones)\n",
    "        augmented_audios.append(pitch_shifted)\n",
    "    except Exception as e:\n",
    "        print(\"Pitch shift error:\", e)\n",
    "    \n",
    "    # Time stretch\n",
    "    try:\n",
    "        rate = np.random.uniform(0.75, 1.25)\n",
    "        time_stretched = librosa.effects.time_stretch(y=audio, rate=rate)\n",
    "        augmented_audios.append(time_stretched)\n",
    "    except Exception as e:\n",
    "        print(\"Time stretch error:\", e)\n",
    "    \n",
    "    # Noise addition\n",
    "    try:\n",
    "        noise = np.random.randn(len(audio)) * 0.005  # Adjust noise level as needed\n",
    "        noisy = audio + noise\n",
    "        augmented_audios.append(noisy)\n",
    "    except Exception as e:\n",
    "        print(\"Noise addition error:\", e)\n",
    "    \n",
    "    return augmented_audios\n",
    "\n",
    "\n",
    "def extract_features_with_augmentation(file_path, h=20, aug_count=0):\n",
    "    \"\"\"\n",
    "    Load an audio file, filter, and extract original MFCCs.\n",
    "    Then generate 'aug_count' augmented versions and extract MFCCs for each.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "        audio = np.ravel(audio)  # ensure 1D\n",
    "        audio_filt = lowpass_filter(audio, sr, cutoff=5000)\n",
    "        \n",
    "        win_length = int(0.025 * sr)\n",
    "        hop_length = int(0.01 * sr)\n",
    "        n_fft = win_length\n",
    "        \n",
    "        # original MFCC\n",
    "        mfcc_orig = librosa.feature.mfcc(\n",
    "            y=audio_filt,\n",
    "            sr=sr,\n",
    "            n_mfcc=h,\n",
    "            n_fft=n_fft,\n",
    "            hop_length=hop_length,\n",
    "            win_length=win_length,\n",
    "            window='hann'\n",
    "        )\n",
    "        outputs = [mfcc_orig]\n",
    "        \n",
    "        if aug_count > 0:\n",
    "            aug_audios = augment_audio(audio_filt, sr)\n",
    "            for i in range(aug_count):\n",
    "                if aug_audios:\n",
    "                    # pick one augmented version from the list\n",
    "                    aug_audio = random.choice(aug_audios)\n",
    "                    aug_audio = np.ravel(aug_audio)  # ensure 1D\n",
    "                    mfcc_aug = librosa.feature.mfcc(\n",
    "                        y=aug_audio,\n",
    "                        sr=sr,\n",
    "                        n_mfcc=h,\n",
    "                        n_fft=n_fft,\n",
    "                        hop_length=hop_length,\n",
    "                        win_length=win_length,\n",
    "                        window='hann'\n",
    "                    )\n",
    "                    outputs.append(mfcc_aug)\n",
    "        return outputs\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def pad_or_truncate(feature_matrix, target_length):\n",
    "    current_length = feature_matrix.shape[1]\n",
    "    if current_length < target_length:\n",
    "        return np.pad(feature_matrix, ((0, 0), (0, target_length - current_length)), mode='constant')\n",
    "    else:\n",
    "        return feature_matrix[:, :target_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MFCC features and applying augmentation for training set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train features: 100%|██████████| 5702/5702 [08:07<00:00, 11.69it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MFCC features for validation set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid features: 100%|██████████| 2000/2000 [00:46<00:00, 42.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MFCC features for test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test features: 100%|██████████| 518/518 [00:17<00:00, 29.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Process Training Data with Augmentation ---\n",
    "all_mfccs_train = []  # Augmented MFCC list (augmented samples will be added)\n",
    "print(\"Extracting MFCC features and applying augmentation for training set:\")\n",
    "\n",
    "for idx, row in tqdm(df_balanced.iterrows(), total=len(df_balanced), desc=\"Train features\"):\n",
    "    file_path = os.path.join(RAW_DATA_DIR, row['filename'])\n",
    "    # resample_factor를 읽습니다.\n",
    "    try:\n",
    "        factor = float(row.get('resample_factor', 1))\n",
    "    except:\n",
    "        factor = 1.0\n",
    "    # 추가로 생성할 augmentation sample 수 = round(factor) - 1, (만약 음수가 나오면 0)\n",
    "    aug_count = max(0, int(round(factor)) - 1)\n",
    "    \n",
    "    mfcc_list = extract_features_with_augmentation(file_path, h=12, aug_count=aug_count)\n",
    "    # mfcc_list는 원본 + 추가 augmented MFCC들을 담은 리스트입니다.\n",
    "    # 각 MFCC의 shape는 (h, time_frames)\n",
    "    # 모든 MFCC sample들을 모두 추가합니다.\n",
    "    all_mfccs_train.extend(mfcc_list)\n",
    "\n",
    "# --- Process Validation Data (원본만 사용) ---\n",
    "all_mfccs_valid = []\n",
    "print(\"Extracting MFCC features for validation set:\")\n",
    "for idx, row in tqdm(df_valid.iterrows(), total=len(df_valid), desc=\"Valid features\"):\n",
    "    file_path = os.path.join(RAW_DATA_DIR, row['filename'])\n",
    "    mfcc = extract_features_with_augmentation(file_path, h=12, aug_count=0)\n",
    "    if mfcc is not None:\n",
    "        all_mfccs_valid.append(mfcc)\n",
    "\n",
    "# --- Process Test Data (원본만 사용) ---\n",
    "all_mfccs_test = []\n",
    "print(\"Extracting MFCC features for test set:\")\n",
    "for idx, row in tqdm(df_test.iterrows(), total=len(df_test), desc=\"Test features\"):\n",
    "    file_path = os.path.join(RAW_DATA_DIR, row['filename'])\n",
    "    mfcc = extract_features_with_augmentation(file_path, h=12, aug_count=0)\n",
    "    if mfcc is not None:\n",
    "        all_mfccs_test.append(mfcc)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median time frames (train augmented): 380\n",
      "Final training audio shape (with augmentation): (8292, 1, 12, 380)\n",
      "Final training label shape: (8292, 4)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# --- Helper function to flatten nested lists of MFCC arrays ---\n",
    "def flatten_mfcc_list(mfcc_list):\n",
    "    flat_list = []\n",
    "    for item in mfcc_list:\n",
    "        # If the item is a list, extend with its contents; else append the item itself\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(item)\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "# --- 맵핑 딕셔너리 정의 ---\n",
    "age_mapping = {\n",
    "    'teens': 10,\n",
    "    'twenties': 20,\n",
    "    'thirties': 30,\n",
    "    'fourties': 40,\n",
    "    'fifties': 50,\n",
    "    'sixties': 60   # 필요에 따라\n",
    "}\n",
    "gender_mapping = {\n",
    "    'male': 0,\n",
    "    'female': 1\n",
    "}\n",
    "\n",
    "# --- 기존 MFCC 전처리 부분 (이미 실행된 코드) ---\n",
    "# (all_mfccs_train, all_mfccs_valid, all_mfccs_test 등)\n",
    "# Flatten the validation and test MFCC lists\n",
    "all_mfccs_valid_flat = flatten_mfcc_list(all_mfccs_valid)\n",
    "all_mfccs_test_flat = flatten_mfcc_list(all_mfccs_test)\n",
    "\n",
    "# --- Determine a common target length for MFCC time frames (training set augmented samples만 사용) ---\n",
    "all_lengths_train = [m.shape[1] for m in all_mfccs_train if m is not None]\n",
    "median_time_frames = int(np.median(all_lengths_train))\n",
    "print(\"Median time frames (train augmented):\", median_time_frames)\n",
    "\n",
    "# --- Pad or truncate each MFCC matrix to the median_time_frames ---\n",
    "padded_mfccs_train = [pad_or_truncate(m, median_time_frames) for m in all_mfccs_train if m is not None]\n",
    "padded_mfccs_valid = [pad_or_truncate(m, median_time_frames) for m in all_mfccs_valid_flat if m is not None]\n",
    "padded_mfccs_test  = [pad_or_truncate(m, median_time_frames) for m in all_mfccs_test_flat if m is not None]\n",
    "\n",
    "# --- Build the final audio array ---\n",
    "# 각 MFCC 샘플은 (1, h, median_time_frames) shape로 확장됨.\n",
    "X_audio_train = np.stack([np.expand_dims(m, axis=0) for m in padded_mfccs_train])\n",
    "X_audio_valid = np.stack([np.expand_dims(m, axis=0) for m in padded_mfccs_valid])\n",
    "X_audio_test  = np.stack([np.expand_dims(m, axis=0) for m in padded_mfccs_test])\n",
    "\n",
    "# --- Build training labels considering augmentation counts ---\n",
    "def build_labels(df, augmentation_counts):\n",
    "    \"\"\"\n",
    "    DataFrame과 각 row가 생성한 총 샘플 개수(augmentation_counts)를 입력받아,\n",
    "    각 row의 label을 해당 개수만큼 복제한 1차원 배열을 반환합니다.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for idx, row in df.iterrows():\n",
    "        count = augmentation_counts[idx]\n",
    "        labels.extend([row['accent_encoded']] * count)\n",
    "    return np.array(labels)\n",
    "\n",
    "# 각 row별 생성 샘플 개수: round(factor) (df_balanced에 'resample_factor' 컬럼이 있다고 가정)\n",
    "augmentation_counts = []\n",
    "for idx, row in df_balanced.iterrows():\n",
    "    try:\n",
    "        factor = float(row.get('resample_factor', 1))\n",
    "    except:\n",
    "        factor = 1.0\n",
    "    total = int(round(factor))\n",
    "    augmentation_counts.append(total)\n",
    "\n",
    "# training label 구축 (accent_encoded 컬럼 사용)\n",
    "y_train_rep = build_labels(df_balanced, augmentation_counts)\n",
    "y_train = to_categorical(y_train_rep)\n",
    "\n",
    "# validation, test set은 원본 그대로 사용\n",
    "y_valid_rep = df_valid['accent_encoded'].values\n",
    "y_valid = to_categorical(y_valid_rep)\n",
    "y_test_rep = df_test['accent_encoded'].values\n",
    "y_test = to_categorical(y_test_rep)\n",
    "\n",
    "print(\"Final training audio shape (with augmentation):\", X_audio_train.shape)\n",
    "print(\"Final training label shape:\", y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- 메타 정보(연령, 성별) 배열 생성 ---\n",
    "def process_meta_value(value, mapping):\n",
    "    \"\"\"\n",
    "    주어진 값이 문자열이면 mapping 딕셔너리를 이용해 처리하고,\n",
    "    그렇지 않으면 정수형으로 변환합니다.\n",
    "    \"\"\"\n",
    "    if isinstance(value, str):\n",
    "        return mapping.get(value.lower(), 0)\n",
    "    else:\n",
    "        try:\n",
    "            return int(value)\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "# Training set: df_balanced에 기반하여 augmentation된 샘플 수만큼 메타정보를 복제\n",
    "meta_train_list = []\n",
    "for idx, row in df_balanced.iterrows():\n",
    "    try:\n",
    "        factor = float(row.get('resample_factor', 1))\n",
    "    except:\n",
    "        factor = 1.0\n",
    "    count = int(round(factor))\n",
    "    # age와 gender 값을 처리: 문자열이면 매핑, 숫자이면 그대로 사용\n",
    "    age_numeric = process_meta_value(row['age'], age_mapping)\n",
    "    gender_numeric = process_meta_value(row['gender'], gender_mapping)\n",
    "    meta_vector = [age_numeric, gender_numeric]\n",
    "    meta_train_list.extend([meta_vector] * count)\n",
    "meta_train = np.array(meta_train_list)\n",
    "\n",
    "# Validation set: augmentation 없음 → 각 row의 메타정보를 그대로 사용\n",
    "meta_valid = []\n",
    "for idx, row in df_valid.iterrows():\n",
    "    age_numeric = process_meta_value(row['age'], age_mapping)\n",
    "    gender_numeric = process_meta_value(row['gender'], gender_mapping)\n",
    "    meta_valid.append([age_numeric, gender_numeric])\n",
    "meta_valid = np.array(meta_valid)\n",
    "\n",
    "# Test set: 동일하게 구성 (df_test에 'age'와 'gender' 컬럼이 있다고 가정)\n",
    "meta_test = []\n",
    "for idx, row in df_test.iterrows():\n",
    "    age_numeric = process_meta_value(row['age'], age_mapping)\n",
    "    gender_numeric = process_meta_value(row['gender'], gender_mapping)\n",
    "    meta_test.append([age_numeric, gender_numeric])\n",
    "meta_test = np.array(meta_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training dataset to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/train-dataset.npz\n",
      "Saved validation dataset to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/valid-dataset.npz\n",
      "Saved test dataset to /Users/jeonsang-eon/ECE6254-Voice-Feature-Extraction/data/test-dataset.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- NPZ 파일로 저장 (MFCC features, labels, 그리고 메타 정보 포함) ---\n",
    "output_dir = os.path.join(BASE_DIR, \"data\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "train_npz_path = os.path.join(output_dir, \"train-dataset.npz\")\n",
    "np.savez_compressed(train_npz_path, X=X_audio_train, y=y_train, meta=meta_train)\n",
    "print(\"Saved training dataset to\", train_npz_path)\n",
    "\n",
    "valid_npz_path = os.path.join(output_dir, \"valid-dataset.npz\")\n",
    "np.savez_compressed(valid_npz_path, X=X_audio_valid, y=y_valid, meta=meta_valid)\n",
    "print(\"Saved validation dataset to\", valid_npz_path)\n",
    "\n",
    "test_npz_path = os.path.join(output_dir, \"test-dataset.npz\")\n",
    "np.savez_compressed(test_npz_path, X=X_audio_test, y=y_test, meta=meta_test)\n",
    "print(\"Saved test dataset to\", test_npz_path)\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
